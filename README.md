# Autograd from scratch
A minimal automatic differentiation engine built from scratch to understand neural network fundamentals. Inspired by Andrej Karpathy's [micrograd](https://github.com/karpathy/micrograd).


# Example Usage


# Quick start

1. Install all dependencies by using a python virtual environment 
2. Download dependencies from `requirements.txt`
3. Start experimenting in a Jupyter notebook!